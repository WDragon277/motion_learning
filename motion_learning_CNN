#텐서플로 워크프레임 적용
#배열 사용을 위한 넘파이 적용
import tensorflow as tf
import numpy as np

#CNN 학습을 위한 batch의 크기와 연산 반복횟수(epochs), 최종 결과 가짓수(num_classes)설정
batch_size = 128
epochs = 8
num_classes = 4

#학습용 데이터와 검사를 위한 데이터를 저장할 변수와 배열 설정
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()  #data module을 위한 tf.data.Dataset API 사용 데이터를 배열로 가져옴
x_train = x_train / 255.0 # 변수 값이 0~255 이므로 255.0으로 나눠서 0~1.0으로 변수를 재설정해줌, 근데 왜 y_데이터는 없냐
x_test = x_test / 255.0 #마찬가지

# 
#이미지 크기를 우리가 계획한 CNN 구조에 맞게 재설정함. 아 어쩌면 우린 일일히 사이즈를 안맞췄어도..됐을지도..물론 지금 자료가 더 정확하겠지만
new_x_train=[] #배열초기화
for ir in range(x_train.shape[0]) # x_train 배열에 데이터 값 넣기 
    new_x_train.append(tf.image.resize(x_train, [84,84], #그림 사이즈 
                    method=ResizeMethod.BILINEAR, 
                    preserve_aspect_ratio=False,
                    antialias=False, 
                    name=None))
#5000,84,84,3

new_y_train=[] 마찬가지임.
for ir in range(x_train.shape[0])
    new_y_train.append(tf.image.resize(y_train, 
                    [84,84], 
                    method=ResizeMethod.BILINEAR, 
                    preserve_aspect_ratio=False,
                    antialias=False, 
                    name=None))


    ---------------------------------------------------------------------------------------------
# one hot encoding으로 변경
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

def build_model(in_shape):
    input_data = tf.keras.layers.Input(shape = (in_shape[1], in_shape[2], in_shape[3]))

    conv2d_1 = tf.keras.layers.Conv2D(input_shape = (in_shape[1], in_shape[2], in_shape[3]),
                               padding='same', 
                               kernel_initializer='glorot_normal', 
                               bias_initializer='zeros', 
                               filters=32, 
                               kernel_size=(3,3),
                               activation='relu')(input_data)
    dropout_1 = tf.keras.layers.Dropout(rate=0.4)(conv2d_1)
    maxpool2d_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(dropout_1)

    conv2d_2 = tf.keras.layers.Conv2D(padding='same', 
                               kernel_initializer='glorot_normal', 
                               bias_initializer='zeros', 
                               filters=64, 
                               kernel_size=(3,3),
                               activation='relu')(maxpool2d_1)
    dropout_2 = tf.keras.layers.Dropout(rate=0.4)(conv2d_2)
    maxpool2d_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(dropout_2)
    
    
    
    flat_1 = tf.keras.layers.Flatten()(maxpool2d_2)
    softmax = tf.keras.layers.Dense(units=num_classes, kernel_initializer='glorot_normal', activation='softmax')(flat_1)
    output_data = softmax

    
    model = tf.keras.models.Model(inputs=[input_data], outputs=[output_data])
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),
                  loss=tf.keras.losses.categorical_crossentropy,
                  metrics=['accuracy'])
    return model

---------------------------------------------------------------------------------------------
if __name__ == '__main__':
    model = build_model(x_train.shape)

    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')
    model.fit(x=x_train, y=y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tensorboard_callback]) 

    train_loss, train_accuracy = model.evaluate(x=x_train, y=y_train)
    print('train data loss:{:2.4f}'.format(train_loss))
    print('train accuracy:{:2.4f}'.format(train_accuracy))

    test_loss, test_accuracy = model.evaluate(x=x_test, y=y_test)
    print('test data loss:{:2.4f}'.format(test_loss))
    print('test accuracy:{:2.4f}'.format(test_accuracy))
    
    model.summary()
    with open('model_report.txt','w') as fh:
        model.summary(print_fn=lambda x: fh.write(x + '\n'))

    model.save('model.h5')
